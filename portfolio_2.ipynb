{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9nbE07myWOkcz3UP+AOYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamdan-Naeem/Particle-Tracking/blob/main/portfolio_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn; seaborn.set_style(\"whitegrid\")\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "\n",
        "if os.path.isdir(\"frames\"):\n",
        "    shutil.rmtree(\"frames\")\n",
        "os.mkdir(\"frames\")\n",
        "\n",
        "if os.path.isfile(\"processed_video.mp4\"):\n",
        "    os.remove(\"processed_video.mp4\")\n",
        "\n",
        "video = cv2.VideoCapture('newdrop(1).mp4')\n",
        "\n",
        "def process_and_save_image(frame, frame_number):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Greyscale allows the image/main object to be picked up easier since it is now black and white\n",
        "    #greyscale_img = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    greyscale_img = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # The blurring degree is used to enhance circle detection by making other images/objects smoother.\n",
        "    blurring_degree = (15, 15)\n",
        "    blurred_img = cv2.blur(greyscale_img, blurring_degree)\n",
        "\n",
        "\n",
        "    # Threshold value\n",
        "    # This turns the image into black-white: pixel intensities lower than the threshold value become black.\n",
        "    # Pixel intensities greater than the threshold value become white.\n",
        "    # This allows the ball to be detected with heavy constrast, since it is black (our object) on a white background\n",
        "    threshold = 200\n",
        "    status, thresholded_img = cv2.threshold(blurred_img, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "    # The following parameters allow the algorithm to detect the ball using specific measurements\n",
        "    # This limits the number of objects that can be detected, while singling out the ball\n",
        "\n",
        "    circles = cv2.HoughCircles(\n",
        "        thresholded_img,\n",
        "        cv2.HOUGH_GRADIENT, 1,\n",
        "        minDist = 40,               # Minimum distance between the detected circles\n",
        "        param1 = 100,               # How strong object edges must be\n",
        "        param2 = 10,                # How perfectly circular the objects must be\n",
        "        minRadius = 30,             # Minimum acceptable circle radius (in pixels)\n",
        "        maxRadius = 50,             # Maximum acceptable circle radius\n",
        "\n",
        "    )\n",
        "\n",
        "    # Plotting the processed images as compiled frames into graphs\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize = (15, 15))\n",
        "\n",
        "    axes[0, 0].set(title = \"Original\")\n",
        "    axes[0, 0].imshow(frame)\n",
        "\n",
        "    axes[0, 1].set(title = \"Greyscaled\")\n",
        "    axes[0, 1].imshow(greyscale_img)\n",
        "\n",
        "    axes[1, 0].set(title = \"Blurred\")\n",
        "    axes[1, 0].imshow(blurred_img)\n",
        "\n",
        "    axes[1, 1].set(title = \"Thresholded - Circle Detection\")\n",
        "    axes[1, 1].imshow(thresholded_img)\n",
        "\n",
        "    if circles is not None:\n",
        "        for circ in circles[0]:\n",
        "            x, y, r = circ\n",
        "            axes[1, 1].add_artist(plt.Circle((x, y), r, fill = False, color = \"red\"))\n",
        "\n",
        "            frame_numbers.append(frame_number)\n",
        "            xpositions.append(frame.shape[1] - x)\n",
        "            ypositions.append(frame.shape[0] - y)\n",
        "            radii.append(r)\n",
        "\n",
        "\n",
        "# Additional graphs to plot the trajectory of the moving ball, frame by frame\n",
        "\n",
        "    axes[0, 2].set(title = \"X-Position\", xlabel = \"Frame Number\", ylabel = \"X (Pixels)\",\n",
        "                   xlim = [0, frame.shape[1]])\n",
        "    axes[0, 2].scatter(frame_numbers, xpositions, s = radii, c = radii)\n",
        "\n",
        "    axes[1, 2].set(title = \"Y-Position\", xlabel = \"Frame Number\", ylabel = \"Y (Pixels)\",\n",
        "                   ylim = [0, frame.shape[0]])\n",
        "    axes[1, 2].scatter(frame_numbers, ypositions, s = radii, c = radii)\n",
        "\n",
        "    # This saves an image of the processed figure. These individual images will be compiled into the video\n",
        "\n",
        "    fig.savefig(f\"frames/frame{frame_number:0>4}.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "frame_numbers = []\n",
        "xpositions = []\n",
        "ypositions = []\n",
        "radii = []\n",
        "\n",
        "# Read in `num_frames` frames and process them; save each resulting figure separately\n",
        "num_frames = 50\n",
        "for i in tqdm(range(num_frames)):\n",
        "    status, frame = video.read()\n",
        "    if status is False:\n",
        "        break\n",
        "\n",
        "    process_and_save_image(frame, i)\n",
        "\n",
        "# Stitching a final video from all the processed frame\n",
        "!ffmpeg -framerate 10 -i frames/frame%04d.png -c:v libx264 -r 30 -pix_fmt yuv420p -hide_banner -loglevel error processed_video.mp4\n",
        "\n",
        "# Final video will be automatically uploaded in the files section\n",
        "show_video(\"processed_video.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc0wq8a1wIjc",
        "outputId": "28f6ad3f-8a97-4bd7-ffad-ad87badbf877",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restitution Coefficient Calculation\n",
        "# A scale factor of 90.0 cm = 1300 pixels\n",
        "# v^2 = u^2 + 2as - calculation of the velocity before collision\n",
        "\n",
        "s_1 = 90 * 0.01                  # Displacement undergone by ball from starting point to end point\n",
        "Initial_velocity = 0             # Ball is being dropped\n",
        "g = 9.81                         # Acceleration due to gravity\n",
        "\n",
        "v_1 = (Initial_velocity + 2*g*s_1)**0.5\n",
        "print(\"Final velocity before collision = \", v_1)\n",
        "\n",
        "# Calculating velcoity after collision\n",
        "Final_velocity = 0                        # Ball reaches zero velocity after converting all\n",
        "                                          # kinetic energy to gravitational potential energy\n",
        "s_2 = 90 * (800/1300) * 0.01              # Displacement undergone by ball from starting point to end point after rebound\n",
        "v_2 = Final_velocity + (2*g*s_2)**0.5     # Velocity after collision\n",
        "Final_velocity = 0\n",
        "print(\"Velocity after collision = \", v_2)\n",
        "\n",
        "# Restituation Coefficient\n",
        "e = v_2/v_1\n",
        "print(\"Restituation coefficient, e = \", e )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ENem1GuZPD",
        "outputId": "9d05f3ae-8fe4-4ee9-b5f9-5012960ad387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final velocity before collision =  4.2021423107743505\n",
            "Velocity after collision =  3.2964316371588143\n",
            "Restituation coefficient, e =  0.7844645405527363\n"
          ]
        }
      ]
    }
  ]
}